---
title: "DM_3"
author: "EL_Hadrami"
date: "19/10/2020"
output: pdf_document
---

```{r}
library(ggpubr)
library(tidyverse)
library(stats)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning = FALSE)
```

```{r}
load("/home/ndoye/Statistics/DM3/mpg.Rdata")
```

```{r}
mpg.r$city_gmp <- 1/(mpg.r$cty)
```

**Exercice 1**

- **Pour la variable cty**

$\underline{\text{a)Test de normalité}}$

```{r}
ctyaut <- mpg.r$cty[mpg.r$trans=="auto"]
shapiro.test(ctyaut)
qqnorm(ctyaut)
```

Soient les deux hypoteses suivantes:

$H_{0}:$ la variable cty derminant la consommation en cycle urbain par la transmission automatique est une loi normale $\\$
$H_{a}:$ la variable cty derminant la consommation en cycle urbain par la transmission mautomatique n'est pas une loi normale $\\$
-Decision

le p-value est inferieur a la valeur de aplha fixée ($\alpha=0.05$), donc on rejette $H_{0}$ et on accepte $H_{a}$ en prenant un risque de  $4.9\%$ de se tromper, cela montre que le test est significatif.

```{r}
ctym <- mpg.r$cty[mpg.r$trans=="manu"]
shapiro.test(ctym)
qqnorm(ctym)
```

Soient les deux hypoteses suivantes:

$H_{0}:$ la variable cty derminant la consommation en cycle urbain par la transmission manuelle est une loi normale $\\$
$H_{a}:$ la variable cty derminant la consommation en cycle urbain par la transmission manuelle n'est pas une loi normale $\\$
-Decision

le p-value est inferieur a la valeur de aplha fixée ($\alpha=0.05$), donc on rejette $H_{0}$ et on accepte $H_{a}$ en prenant un risque de  $4.98\%$ de se tromper, ce qui montre que le test est significatif.

$\underline{\text{b)Pour la variable citygmp}}$

```{r}
cga <- mpg.r$city_gmp[mpg.r$trans=="auto"]
df3 <- data.frame(cga)
shapiro.test(cga)
qqnorm(cga)
```

Soient les deux hypoteses suivantes:$\\$
$H_{0}:$ la variable city_gmp derminant la consommattion par distance parcourue est une loi normale $\\$
$H_{a}:$ la variable cty derminant la consommation par distance parcourue n'est pas une loi normale $\\$
-Decision$\\$
le p-value est inferieur a la valeur de aplha fixée ($\alpha=0.05$), donc on rejette $H_{0}$ et on accepte $H_{a}$ en prenant un risque de  $4.99\%$ de se tromper, ce qui montre que le test est significative.


```{r}
cgm <- mpg.r$city_gmp[mpg.r$trans=="manu"]
shapiro.test(cgm)
qqnorm(cgm)
```

Soient les deux hypoteses suivantes:$\\$
$H_{0}:$ la variable city_gmp derminant la consommattion par distance parcourue est une loi normale $\\$
$H_{a}:$ la variable cty derminant la consommation par distance parcourue n'est pas une loi normale $\\$
-Decision$\\$
le p-value est inferieur a la valeur de aplha fixée ($\alpha=0.05$), donc on rejette $H_{0}$ et on accepte $H_{a}$ en prenant un risque de  $4.986\%$ de se tromper, ce qui montre que le test est significative.

$\underline{\text{c)Test d'egalité des variances}}\\$
```{r}
var.test(mpg.r$cty ~ trans,data=mpg.r)
t.test(mpg.r$cty~trans,data=mpg.r)$conf.int # intervall de confiance pour la variable cty
```
Soient les deux hypoteses suivantes:$\\$
$H_{0}:$ la variance de la variable cty est identique entre les deux types de transmission(automatique et manuelle)$\\$
$H_{a}:$ la variance de la variable cty est different entre les deux types de transmission(automatique et manuelle)$\\$
-Decision$\\$
le p-value est superieur a la valeur de alpha fixée ($\alpha=0.05$), donc on rejette $H_{a}$ et on accepte $H_{0}$ avec un risque de $6.01\%$ de se tromper,cela montre qu'il y a une difference significative entre les types de transmission(manuelle et automatique) sur la consommation en cycle urbain  

$\text{d)}\\$
```{r}
pairwise.t.test(mpg.r$cty,mpg.r$trans, pool.sd = TRUE,
p.adjust.method = "none")
```
soient les deux hypotheses suivantes

$\text{Decision}\\$
le p-value est inferieur a la valeur de aplha fixée ($\alpha=0.05$), donc on rejette $H_{0}$ et on accepte $H_{a}$ en prenant un risque de  $4.23\%$ de se tromper, cela montre qu'il y a une difference significative entre la .


-**Pour la variable hwy**$\\$
$\underline{\text{Test de normalité}}$

```{r}
hwyaut <- mpg.r$hwy[mpg.r$trans=="auto"]
shapiro.test(hwyaut)
qqnorm(hwyaut)
```

Soient les deux hypoteses suivantes:$\\$
$H_{0}:$ la variable hwy derminant la consommation sur l’autoroute par la transmission automatique est une loi normale $\\$
$H_{a}:$ la variable hwy derminant la consommation sur l’autoroute par la transmission automatique n'est pas une loi normale $\\$
$\text{Decision}$

le p-value est inferieur a la valeur de aplha fixée ($\alpha=0.05$), donc on rejette $H_{0}$ et on accepte $H_{a}$ en prenant un risque de  $4.99\%$ de se tromper.

```{r}
hwym <- mpg.r$hwy[mpg.r$trans=="manu"]
shapiro.test(hwym)
qqnorm(hwym)
```

Soient les deux hypoteses suivantes:$\\$
$H_{0}:$ la variable hwy qui dermine  la consommation sur l’autoroute par la transmission manuelle est une loi normale $\\$
$H_{a}:$ la variable hwy qui determine la consommation sur l’autoroute par la transmission manuelle n'est pas une loi normale $\\$
$\text{Decision}$

le p-value est inferieur a la valeur de aplha fixée ($\alpha=0.05$), donc on rejette $H_{0}$ et on accepte $H_{a}$ en prenant un risque de  $4.77\%$ de se tromper.

$\text{test d'egalité des variances}$

```{r}
var.test(mpg.r$hwy ~ trans,data=mpg.r)
t.test(mpg.r$hwy~trans,data=mpg.r)$conf.int # intervalle de confiance
```

Soient les deux hypoteses suivantes:$\\$
$H_{0}:$ la variance de la variable hwy est identique entre les deux types de transmission(automatique et manuelle)$\\$
$H_{a}:$ la variance de la variable hwy est différente entre les deux types de transmission(automatique et manuelle)$\\$
-Decision$\\$
le p-value est superieur a la valeur de alpha fixée ($\alpha=0.05$), donc on rejette $H_{a}$ et on accepte $H_{0}$ avec un risque de $48.75\%$ de se tromper, cela montre qu'il y a une difference significative entre les types de transmission(manuelle et automatique) sur la consommation en autouroute. 


$\text{2.d)}$

```{r}
pairwise.t.test(mpg.r$hwy,mpg.r$trans, pool.sd = TRUE,
p.adjust.method = "none")
```

**Exercice 2**

```{r}
alternativef <- function(t,df,alternative){
  if (alternative=="two.sided"){
    p_value <- 2*pt(abs(t),df,lower.tail = FALSE)
    return (p_value)
  }
  if (alternative=="less"){
    p_value <- pt(t,df)
    return(p_value)
  }
   if (alternative=="greater"){
    p_value <- pt(t,df,lower.tail = FALSE)
    return(p_value)
  }
}
```
```{r}
myt.test <- function(x,y,alternative,paired,var.equal){
  nx <- length(x)
  ny <- length(y)
  d <- x-y
    if(paired==TRUE){
      t <- mean(d) / sqrt(var(d)/nx)
      df <- nx - 1 
      pvalue <- alternativef(t,df,alternative)
      return(list("Student two paired sample t-test",alternative,p.value=pvalue,df=df,statistics=t))
    }
    if(var.equal==FALSE){
      sqrt1 <- sqrt(var(x)/nx)
      sqrt2 <- sqrt(var(y)/ny)
      w <- mean(x) - mean(y) / sqrt1 + sqrt2
      s_carre_x_n_x <- var(x)/nx
      s_carre_y_n_y <- var(y)/ny
      df <- (s_carre_x_n_x +  s_carre_y_n_y)^2/((1/(nx-1)) * s_carre_x_n_x^2 + 
            (1/(ny-1))*(s_carre_y_n_y^2))
      pvalue <- alternativef(w,df,alternative)
      return(list("Welch two sample t-test",alternative,p.value=pvalue,df=df,statistics=w))
    }
    if(var.equal==TRUE){
      s_carré <- (length(x) - 1) * var(x) + (ny - 1) * var(y) / (nx + ny - 2)
      t <- (mean(x) - mean(y)) / (sqrt(s_carré)*(1/nx) + 1/ny)
      df <- nx + ny - 2
      pvalue <- alternativef(t,df,alternative)
      return(list("Student two samplet-test",alternative,p.value=pvalue,df=df,statistics=t))
    }
}
```

test 
  
```{r}
# deux vecteur de meme taille 
x <- c(0.5548773,  1.1915892, -0.4580385, -0.1115346,  0.8131957,  1.5057274,0.2969755, 
       0.3173708, 1.9979060, -0.3039169,  0.121106)
y <- c(0.6483476,  1.8113529,  2.0418074,  0.9330143,  1.2162020,  
        0.4360250,0.8259032, 0.8762932, -0.3322635,-0.3039169,  0.121106)
myt.test(x, y,alternative = "greater",paired = TRUE, var.equal = FALSE)
t.test(x, y,alternative = "greater",paired = TRUE, var.equal = FALSE)
```


**Exercice 3**


```{r}
# importation des données
data_diamonds <- read.delim("/home/ndoye/Statistics/DM3/diamonds.dat",sep="")
summary(data_diamonds)
# extraction d'un data frame prix et clarté
Price <- data_diamonds$Price
Clarity <- data_diamonds$Clarity
df_price_clarity <- data.frame(Price,Clarity)
summary(df_price_clarity)
mean_IF <- mean(Price[Clarity=="IF"])
mean_VVS1 <- mean(Price[Clarity=="VVS1"])
mean_VVS2 <- mean(Price[Clarity=="VVS2"])
mean_VS1 <- mean(Price[Clarity=="VS1"])
mean_VS2 <- mean(Price[Clarity=="VS2"])
mean_price <- c(mean_IF,mean_VVS1,mean_VVS2,mean_VS1,mean_VS2)
clarity <- c("IF","VVS1","VVS2","VS1","VS2")
dfmean <- data.frame(mean_price,clarity)
g1 <- ggplot(data = dfmean) + 
geom_bar(stat="identity",mapping = aes(x = clarity,y = mean_price,fill=clarity)) + 
geom_text(aes(x=clarity,y=mean_price/2,label=(round(mean_price,2))),position = "dodge") +
ggtitle("Diagramme en bâton representant les moyennes des cinq clartée ") 
g1 + theme (plot.title = element_text(size=11,face="bold",hjust = 0.5))
```

Le barplot montre le prix moyen d'un diamant selon sa clartée, on constate que le prix d'un diamant varie en fonction de sa clartée, par exemple: un diamant de clartée IF est beaucoup moins chers que les autre diamants et un diamant de clartée VS2 est beaucoup plus chers que tous les autres diamants.

```{r}
g2 <- ggplot(df_price_clarity,aes(Clarity,Price, fill=Clarity)) + geom_boxplot() +
      stat_summary(aes(y = Price),
      fun = "mean",color="red", fill="red") + stat_summary(aes(y = Price),fun="median",color="blue", fill="blue") + ggtitle("Boite a moustache")
g2 + theme (plot.title = element_text(size=11,face="bold",hjust = 0.5))
```

Cette image montre le boxplot des prix de diamants en fonction de leurs groupes de clartée, les points bleus et rouges qui se trouvent sur chaque boxplot indique la mediane et la moyenne des groupes de clarté, on observe aussi des valeurs aberrantes dans chaque boxplot

**Question 3**

Apres avoir fait le barplot sur les prix moyens des diamants en fonction de leur clartée, on constate qu'il y a une difference significative entre le prix de diamant de clarté "IF" et les autres groupe de clarté, car le prix moyen de diamants de clarté IF est largement inferieur aux prix moyen des diamants des autres groupes de clarté.

**Question 4:analyse de variance**

soient les notations suivantes:
IF, VVS1, VVS2, VS1, VS2 $\\$
$\mu_{if}:$ le prix moyen d'un diamant de clarté "IF" $\\$
$\mu_{vvs1}:$ le prix moyen d'un diamant de clarté "VVS1" $\\$
$\mu_{vvs2}:$ le prix moyen d'un diamant de clarté "VVS2" $\\$
$\mu_{vs1}:$ le prix moyen d'un diamant de clarté "VS1" $\\$ 
$\mu_{vs2}:$ le prix moyen d'un diamant de clarté "IF" $\\$
soient les deux hypothéses suivantes:$\\$
$H_{0}:\mu_{if}=\mu_{vvs1}=\mu_{vvs2}=\mu_{vs1}=\mu_{vs2}\\$
$H_{a}: \exists \ i,j\in \{if,vvs1,vvs2,vs1,vs2\}$ tels que $\mu_{i}\ne\mu_{j}$

```{r}
An_var <- lm(Price~Clarity)
anova(An_var)
```

$\underline{\alpha=0.01}\\$
- Decision: $\\$
le p-value est superieur a la valeur de alpha fixée $(\alpha=0.01)$, donc  on rejete l'hypotése $H_{a}$ et on accepte l'hypotése nulle($H_{0}$) en prenant un risque de $0.49\%$ de se tromper ce qui est quasiment faible cela montre qu'il n y a pas une difference significative entre le prix moyen des groupements de clarté.$\\$ 
$\underline{\alpha=0.05}\\$
- Decision: $\\$
le p-value est inferieur a la valeur de aplha fixée $(\alpha=0.05)$, donc  on rejette $H_{0}$ et on accepte l'hypothése $H_{a}$ avec un risque de $3.5\%$ de se tromper, ce qui montre qu'il y a une dependance significative entre le prix d'un diamant et son groupe de clarté.

$\textbf{Question 5}$

$\underline{\text{Test de fisher}}$
```{r}
pairwise.t.test(Price, Clarity, pool.sd = TRUE,
p.adjust.method = "none")
```

$\underline{\text{test de Tukey}}$

```{r}
df_price_clarity.aov <- aov(Price~Clarity)
TukeyHSD(df_price_clarity.aov)
```

$\underline{\text{test de Bonferroni}}$

```{r}
pairwise.t.test(Price, Clarity, pool.sd = TRUE,
p.adjust.method = "bonf")
```

Apres avoir fait les trois tests on constate que le test de fisher et de Tukey donnent des p-value quasi-identiques,par contre le test de bonferonni donne des pvalue qui sont differentes aux deux premiers tests, ce qui montre l'apparition des regroupements differentes.
Cette difference s'explique le fait que la methode de fisher et Tukey testent l'egalité de deux variances et la methode de bonferroni teste l'egalité de deux moyennes, la methode de bonferonni donne le regroupement le plus grossier, car elle retourne plusieurs p-value qui sont egal a $1$ dans ces cas on ne peut pas accepter l'hypothése d'egalité des moyennes avec un risque de  $95\%$ qui est trés elevé .

$\textbf{Question 6}$

Oui il y a une coherence entre le test de fisher dans la question 4 et les comparaisons multiples avec la question 3 car dans tous les tests on observe sur certains regroupement un pvalue inferieur a $0.01$ ou a $0.05$ ce qui explique la  difference significative entre les prix de diamant et leur clarté.

$\textbf{Question 7}\\$
D'apres le diagramme en baton representant le prix moyen des diamants en fonction de leur groupe de clarté on constate que les prix moyens de diamants sont differents donc on rejete l'hypothese de normalité des prix, dans certains cas le test de fisher donne un p-value superieur a $0.05$ donc l’hypothèse des variances égale d’un groupe à l’autre peut etre accepté.

$\underline{\text{Test de Bartlett}}$
  
```{r}
bartlett.test(Price ~ Clarity, data = df_price_clarity)
boxplot(Price~Clarity)
```

le test de bartlett donne un p-value de $0.6407$ qui est largement superieur a $0.05$ donc on accepte l'hypothése d'egalité des variances avec un risque de $59.07\%$ de se tromper.